
### Answer Key

#### Multiple Choice

1. B
2. B
3. B
4. A
5. B

#### Short Answer

6. Tokenization is the process of breaking down a text into smaller pieces, commonly known as tokens. It is a crucial step in text preprocessing for NLP tasks.

7. NLTK is more academic and comprehensive, offering a wide range of tools and algorithms for NLP. SpaCy, on the other hand, is designed for industrial applications and focuses on performance and efficiency.

8. Named Entity Recognition (NER) is the task of identifying and classifying named entities in text, such as names of persons, organizations, locations, etc. It is crucial for information extraction and knowledge graph construction.

9. Word Embeddings are dense vectors that capture the semantic meaning of words based on their context. They are significant for various NLP tasks like text classification, sentiment analysis, and machine translation.

10. Common evaluation metrics in NLP include accuracy, precision, recall, F1-score, BLEU for machine translation, and ROUGE for text summarization.

#### Code Snippet

11-15. Answers may vary but should demonstrate the correct implementation of the respective tasks.

#### True or False

16. False
17. True
18. False

#### Fill in the Blanks

19. Vectorization
20. BLEU

This quiz should serve as a comprehensive assessment for Week 11, covering the breadth of Natural Language Processing.
